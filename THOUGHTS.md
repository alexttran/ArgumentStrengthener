# Development Reflections

## How did you use LLMs in your project?

LLMs are the core intelligence of this application, serving as the analytical engine that transforms user arguments into comprehensive, multi-faceted critiques. I integrated OpenAI's GPT-5 model through their official Node.js SDK, using it as an on-demand analysis service rather than a conversational agent. The key innovation is in the prompt engineering: I crafted a system prompt that positions the AI as an "expert critical thinker and debate coach," explicitly instructing it to generate steelman (not strawman) counterarguments and to avoid bias. The user prompt requests structured JSON output with five specific components (steelman counter, weak points, misconceptions, reinforcements, and opposing responses), ensuring consistent, parseable results every time. This structured approach treats the LLM as a specialized function that takes an argument string and returns a comprehensive analysis object, making the integration clean and predictable.

## What was the biggest challenge and how did you solve it?

The biggest challenge was ensuring reliable, structured output from the LLM that could be consistently parsed and displayed in the UI. Initially, I experimented with free-form text responses, but they were inconsistent in format and difficult to parse into the five distinct sections I needed. The breakthrough came from using OpenAI's JSON mode (response_format: { type: 'json_object' }), which guarantees the model will return valid JSON. However, this required careful prompt engineering to specify the exact schema I wanted, including field names, data types, and minimum item counts for arrays. I solved the parsing reliability issue by providing an explicit JSON template in the user prompt, showing the model exactly what structure to follow. Additionally, I added fallback empty values (|| '') in the parsing logic to handle any edge cases where the model might omit a field. This combination of JSON mode, explicit schema specification, and defensive parsing created a robust pipeline that has proven reliable across diverse argument types.

## If you had one more week, what would you improve or extend?

With one more week, I would first implement features to tune the response, where the user can choose the tone or harshness that is outputed. I think another large improvement that could be made is the ability for the user to have a back and forth with the LLM to strengthen their argument, where the user can practice giving their argument. Additionally, I would try to implement authentication and accounts, paired with a PostgreSQL database so that a user can look back at the feedback without having to redo the process. There also needs to be more development with the prompt engineering to make sure that all the responses and inputs are safe and appropriate. 
